{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(channelindex,x_train,length,y_train):\n",
    "    \"\"\"choose images of same channel from three rdgs and depth into a group of 4 images\"\"\"\n",
    "    im0=[(normalize(x_train[0][i][0][channelindex]),normalize(x_train[0][i][1][channelindex]),\\\n",
    "        normalize(x_train[0][i][2][channelindex]),normalize(x_train[1][i][channelindex]),y_train[0][i]) for i in range(length)]\n",
    "    random.shuffle(im0)\n",
    "    return im0\n",
    "\n",
    "def choose2(positionindex,x_train,length,y_train):\n",
    "    \"\"\"choose rdg images of one angle, three channels and depth image of three channels\"\"\"\n",
    "    im0=[(normalize(x_train[0][i][0][positionindex]),normalize(x_train[0][i][1][positionindex]),\\\n",
    "        normalize(x_train[0][i][2][positionindex]),normalize(x_train[1][i][0]),normalize(x_train[1][i][1]),normalize(x_train[1][i][2]),\\\n",
    "            y_train[0][i]) for i in range(length)]\n",
    "    random.shuffle(im0)\n",
    "    return im0\n",
    "\n",
    "def lazychoose(length):\n",
    "    \"\"\"load all the images from lazydata and normalize\"\"\"\n",
    "    total=[]\n",
    "    for i in range(length):\n",
    "        data=[]\n",
    "        im0=torch.tensor(cv2.normalize(cv2.imread(\"lazydata/train/X/\"+str(i)+\"/rgb/0.png\"), None, alpha=0, beta=1,\n",
    "                             norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F))\n",
    "        \n",
    "        im0=torch.permute(im0,(2,0,1))\n",
    "    \n",
    "        im1=torch.tensor(cv2.normalize(cv2.imread(\"lazydata/train/X/\"+str(i)+\"/rgb/1.png\"), None, alpha=0, beta=1,\n",
    "                             norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F))\n",
    "        \n",
    "        im1=torch.permute(im1,(2,0,1))\n",
    "      \n",
    "        im2=torch.tensor(cv2.normalize(cv2.imread(\"lazydata/train/X/\"+str(i)+\"/rgb/2.png\"), None, alpha=0, beta=1,\n",
    "                             norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F))\n",
    "        im2=torch.permute(im2,(2,0,1))\n",
    "    \n",
    "        depth=torch.tensor(cv2.normalize(np.load(\"lazydata/train/X/\"+str(i)+\"/depth.npy\"), None, alpha=0, beta=1,\n",
    "                             norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F))\n",
    "        \n",
    "\n",
    "        y=np.load(\"lazydata/train/Y/\"+str(i)+\".npy\")\n",
    "        data.append(im0)\n",
    "        data.append(im1)\n",
    "        data.append(im2)\n",
    "        data.append(depth)\n",
    "        data.append(y)\n",
    "        total.append(data)\n",
    " \n",
    "    train_loader = torch.utils.data.DataLoader(total, batch_size=1, shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "def normalize(image):\n",
    "    \"\"\"normalize function for choose and choose2\"\"\"\n",
    "    image=np.array(image)\n",
    "    mean=np.mean(image)\n",
    "    var=np.mean(np.square(image-mean))\n",
    "    image=(image-mean)/np.sqrt(var)\n",
    "\n",
    "    return torch.tensor(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chan1=lazychoose(3396)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"CNN with 2 layers\"\"\"\n",
    "    def __init__(self, input_size, conv_feature, fc_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=conv_feature, kernel_size=50),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(72),\n",
    "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(72),\n",
    "            nn.MaxPool2d(kernel_size=20,stride=10),\n",
    "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(72),\n",
    "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(72),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=conv_feature, out_channels=conv_feature, kernel_size=5), \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            )\n",
    "        self.linear_layers=nn.Sequential(\n",
    "            nn.Linear(conv_feature*4*4, fc_feature),\n",
    "            nn.ReLU(),\n",
    "           \n",
    "            nn.Linear(fc_feature, output_size),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.linear_layers(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch, model, optimizer, chan):\n",
    "    \n",
    "    for batch_ind,a in enumerate(chan):\n",
    "        \n",
    "        image=torch.stack((a[0][:,0],a[0][:,1],a[0][:,2],\\\n",
    "            a[1][:,0],a[1][:,1],a[1][:,2],a[2][:,0],a[2][:,1],\\\n",
    "                a[2][:,2],a[3][:,0],a[3][:,1],a[3][:,2]),1)\n",
    "\n",
    "\n",
    "        target=torch.squeeze(a[4])\n",
    "\n",
    "        image, target = image.to(device), target.to(device)       \n",
    "\n",
    "        output = model(image)\n",
    "        loss = F.mse_loss(output.float(),target.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_ind % 52 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_ind * len(image), len(chan.dataset),\n",
    "                100. * batch_ind/ len(chan), loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3396 (0%)]\tLoss: 1.240531\n",
      "Train Epoch: 0 [800/3396 (23%)]\tLoss: 0.545399\n",
      "Train Epoch: 0 [1600/3396 (47%)]\tLoss: -3.185933\n",
      "Train Epoch: 0 [2400/3396 (70%)]\tLoss: 0.328922\n",
      "Train Epoch: 0 [3200/3396 (93%)]\tLoss: -0.867656\n",
      "Train Epoch: 1 [0/3396 (0%)]\tLoss: 1.087387\n",
      "Train Epoch: 1 [800/3396 (23%)]\tLoss: 1.034269\n",
      "Train Epoch: 1 [1600/3396 (47%)]\tLoss: 0.745285\n",
      "Train Epoch: 1 [2400/3396 (70%)]\tLoss: 1.173002\n",
      "Train Epoch: 1 [3200/3396 (93%)]\tLoss: 0.939948\n"
     ]
    }
   ],
   "source": [
    "conv_features = 72\n",
    "fc_features = 50\n",
    "output_size = 12\n",
    "model_cnn = CNN(224*224,conv_features,fc_features,output_size) \n",
    "\n",
    "model_cnn.to(device)\n",
    "optimizer = torch.optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.7)\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(0, 2):\n",
    "    train(epoch, model_cnn, optimizer,train_loader)\n",
    "    train_loader = torch.utils.data.DataLoader(chan1, batch_size=32, shuffle=True)\n",
    "\n",
    "torch.save(model_cnn.state_dict(), \"model_cnn_2.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Users\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "'''load pretrained weight'''\n",
    "res=torchvision.models.resnet50(pretrained=True)\n",
    "print(res.conv1)\n",
    "res.conv1=nn.Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "print(res.conv1)\n",
    "num_ftrs = res.fc.in_features\n",
    "print(num_ftrs)\n",
    "del res.fc\n",
    "res.add_module(\"fc\", nn.Sequential(nn.Linear(num_ftrs, 800),nn.ReLU(),nn.Linear(800, 200),nn.ReLU(),nn.Linear(200, 12)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruokai Gu\\AppData\\Local\\Temp\\ipykernel_3300\\177351430.py:58: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([1, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(output.float(),target.float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3396 (0%)]\tLoss: 0.015337\n",
      "Train Epoch: 0 [52/3396 (2%)]\tLoss: 0.000904\n",
      "Train Epoch: 0 [104/3396 (3%)]\tLoss: 0.000325\n",
      "Train Epoch: 0 [156/3396 (5%)]\tLoss: 0.000369\n",
      "Train Epoch: 0 [208/3396 (6%)]\tLoss: 0.000372\n",
      "Train Epoch: 0 [260/3396 (8%)]\tLoss: 0.001400\n",
      "Train Epoch: 0 [312/3396 (9%)]\tLoss: 0.001334\n",
      "Train Epoch: 0 [364/3396 (11%)]\tLoss: 0.000414\n",
      "Train Epoch: 0 [416/3396 (12%)]\tLoss: 0.000296\n",
      "Train Epoch: 0 [468/3396 (14%)]\tLoss: 0.000432\n",
      "Train Epoch: 0 [520/3396 (15%)]\tLoss: 0.000322\n",
      "Train Epoch: 0 [572/3396 (17%)]\tLoss: 0.000200\n",
      "Train Epoch: 0 [624/3396 (18%)]\tLoss: 0.000363\n",
      "Train Epoch: 0 [676/3396 (20%)]\tLoss: 0.000120\n",
      "Train Epoch: 0 [728/3396 (21%)]\tLoss: 0.000235\n",
      "Train Epoch: 0 [780/3396 (23%)]\tLoss: 0.000629\n",
      "Train Epoch: 0 [832/3396 (24%)]\tLoss: 0.000502\n",
      "Train Epoch: 0 [884/3396 (26%)]\tLoss: 0.000495\n",
      "Train Epoch: 0 [936/3396 (28%)]\tLoss: 0.000252\n",
      "Train Epoch: 0 [988/3396 (29%)]\tLoss: 0.000417\n",
      "Train Epoch: 0 [1040/3396 (31%)]\tLoss: 0.000693\n",
      "Train Epoch: 0 [1092/3396 (32%)]\tLoss: 0.000202\n",
      "Train Epoch: 0 [1144/3396 (34%)]\tLoss: 0.000640\n",
      "Train Epoch: 0 [1196/3396 (35%)]\tLoss: 0.000417\n",
      "Train Epoch: 0 [1248/3396 (37%)]\tLoss: 0.000172\n",
      "Train Epoch: 0 [1300/3396 (38%)]\tLoss: 0.000131\n",
      "Train Epoch: 0 [1352/3396 (40%)]\tLoss: 0.000215\n",
      "Train Epoch: 0 [1404/3396 (41%)]\tLoss: 0.000159\n",
      "Train Epoch: 0 [1456/3396 (43%)]\tLoss: 0.000261\n",
      "Train Epoch: 0 [1508/3396 (44%)]\tLoss: 0.000109\n",
      "Train Epoch: 0 [1560/3396 (46%)]\tLoss: 0.000084\n",
      "Train Epoch: 0 [1612/3396 (47%)]\tLoss: 0.000145\n",
      "Train Epoch: 0 [1664/3396 (49%)]\tLoss: 0.000178\n",
      "Train Epoch: 0 [1716/3396 (51%)]\tLoss: 0.000070\n",
      "Train Epoch: 0 [1768/3396 (52%)]\tLoss: 0.000194\n",
      "Train Epoch: 0 [1820/3396 (54%)]\tLoss: 0.000062\n",
      "Train Epoch: 0 [1872/3396 (55%)]\tLoss: 0.000057\n",
      "Train Epoch: 0 [1924/3396 (57%)]\tLoss: 0.000046\n",
      "Train Epoch: 0 [1976/3396 (58%)]\tLoss: 0.000084\n",
      "Train Epoch: 0 [2028/3396 (60%)]\tLoss: 0.000139\n",
      "Train Epoch: 0 [2080/3396 (61%)]\tLoss: 0.000404\n",
      "Train Epoch: 0 [2132/3396 (63%)]\tLoss: 0.000080\n",
      "Train Epoch: 0 [2184/3396 (64%)]\tLoss: 0.000092\n",
      "Train Epoch: 0 [2236/3396 (66%)]\tLoss: 0.000072\n",
      "Train Epoch: 0 [2288/3396 (67%)]\tLoss: 0.000102\n",
      "Train Epoch: 0 [2340/3396 (69%)]\tLoss: 0.000110\n",
      "Train Epoch: 0 [2392/3396 (70%)]\tLoss: 0.000043\n",
      "Train Epoch: 0 [2444/3396 (72%)]\tLoss: 0.000036\n",
      "Train Epoch: 0 [2496/3396 (73%)]\tLoss: 0.000305\n",
      "Train Epoch: 0 [2548/3396 (75%)]\tLoss: 0.000116\n",
      "Train Epoch: 0 [2600/3396 (77%)]\tLoss: 0.000141\n",
      "Train Epoch: 0 [2652/3396 (78%)]\tLoss: 0.000204\n",
      "Train Epoch: 0 [2704/3396 (80%)]\tLoss: 0.000017\n",
      "Train Epoch: 0 [2756/3396 (81%)]\tLoss: 0.000074\n",
      "Train Epoch: 0 [2808/3396 (83%)]\tLoss: 0.000035\n",
      "Train Epoch: 0 [2860/3396 (84%)]\tLoss: 0.000020\n",
      "Train Epoch: 0 [2912/3396 (86%)]\tLoss: 0.000047\n",
      "Train Epoch: 0 [2964/3396 (87%)]\tLoss: 0.000226\n",
      "Train Epoch: 0 [3016/3396 (89%)]\tLoss: 0.000138\n",
      "Train Epoch: 0 [3068/3396 (90%)]\tLoss: 0.000065\n",
      "Train Epoch: 0 [3120/3396 (92%)]\tLoss: 0.000048\n",
      "Train Epoch: 0 [3172/3396 (93%)]\tLoss: 0.000059\n",
      "Train Epoch: 0 [3224/3396 (95%)]\tLoss: 0.000035\n",
      "Train Epoch: 0 [3276/3396 (96%)]\tLoss: 0.000069\n",
      "Train Epoch: 0 [3328/3396 (98%)]\tLoss: 0.000082\n",
      "Train Epoch: 0 [3380/3396 (100%)]\tLoss: 0.000046\n",
      "Train Epoch: 1 [0/3396 (0%)]\tLoss: 0.000055\n",
      "Train Epoch: 1 [52/3396 (2%)]\tLoss: 0.000070\n",
      "Train Epoch: 1 [104/3396 (3%)]\tLoss: 0.000097\n",
      "Train Epoch: 1 [156/3396 (5%)]\tLoss: 0.000123\n",
      "Train Epoch: 1 [208/3396 (6%)]\tLoss: 0.000047\n",
      "Train Epoch: 1 [260/3396 (8%)]\tLoss: 0.000024\n",
      "Train Epoch: 1 [312/3396 (9%)]\tLoss: 0.000078\n",
      "Train Epoch: 1 [364/3396 (11%)]\tLoss: 0.000042\n",
      "Train Epoch: 1 [416/3396 (12%)]\tLoss: 0.000054\n",
      "Train Epoch: 1 [468/3396 (14%)]\tLoss: 0.000028\n",
      "Train Epoch: 1 [520/3396 (15%)]\tLoss: 0.000035\n",
      "Train Epoch: 1 [572/3396 (17%)]\tLoss: 0.000016\n",
      "Train Epoch: 1 [624/3396 (18%)]\tLoss: 0.000016\n",
      "Train Epoch: 1 [676/3396 (20%)]\tLoss: 0.000036\n",
      "Train Epoch: 1 [728/3396 (21%)]\tLoss: 0.000017\n",
      "Train Epoch: 1 [780/3396 (23%)]\tLoss: 0.000014\n",
      "Train Epoch: 1 [832/3396 (24%)]\tLoss: 0.000025\n",
      "Train Epoch: 1 [884/3396 (26%)]\tLoss: 0.000035\n",
      "Train Epoch: 1 [936/3396 (28%)]\tLoss: 0.000052\n",
      "Train Epoch: 1 [988/3396 (29%)]\tLoss: 0.000048\n",
      "Train Epoch: 1 [1040/3396 (31%)]\tLoss: 0.000145\n",
      "Train Epoch: 1 [1092/3396 (32%)]\tLoss: 0.000076\n",
      "Train Epoch: 1 [1144/3396 (34%)]\tLoss: 0.000043\n",
      "Train Epoch: 1 [1196/3396 (35%)]\tLoss: 0.000029\n",
      "Train Epoch: 1 [1248/3396 (37%)]\tLoss: 0.000029\n",
      "Train Epoch: 1 [1300/3396 (38%)]\tLoss: 0.000038\n",
      "Train Epoch: 1 [1352/3396 (40%)]\tLoss: 0.000009\n",
      "Train Epoch: 1 [1404/3396 (41%)]\tLoss: 0.000080\n",
      "Train Epoch: 1 [1456/3396 (43%)]\tLoss: 0.000054\n",
      "Train Epoch: 1 [1508/3396 (44%)]\tLoss: 0.000058\n",
      "Train Epoch: 1 [1560/3396 (46%)]\tLoss: 0.000029\n",
      "Train Epoch: 1 [1612/3396 (47%)]\tLoss: 0.000018\n",
      "Train Epoch: 1 [1664/3396 (49%)]\tLoss: 0.000026\n",
      "Train Epoch: 1 [1716/3396 (51%)]\tLoss: 0.000045\n",
      "Train Epoch: 1 [1768/3396 (52%)]\tLoss: 0.000031\n",
      "Train Epoch: 1 [1820/3396 (54%)]\tLoss: 0.000004\n",
      "Train Epoch: 1 [1872/3396 (55%)]\tLoss: 0.000042\n",
      "Train Epoch: 1 [1924/3396 (57%)]\tLoss: 0.000012\n",
      "Train Epoch: 1 [1976/3396 (58%)]\tLoss: 0.000092\n",
      "Train Epoch: 1 [2028/3396 (60%)]\tLoss: 0.000011\n",
      "Train Epoch: 1 [2080/3396 (61%)]\tLoss: 0.000077\n",
      "Train Epoch: 1 [2132/3396 (63%)]\tLoss: 0.000010\n",
      "Train Epoch: 1 [2184/3396 (64%)]\tLoss: 0.000041\n",
      "Train Epoch: 1 [2236/3396 (66%)]\tLoss: 0.000017\n",
      "Train Epoch: 1 [2288/3396 (67%)]\tLoss: 0.000076\n",
      "Train Epoch: 1 [2340/3396 (69%)]\tLoss: 0.000019\n",
      "Train Epoch: 1 [2392/3396 (70%)]\tLoss: 0.000011\n",
      "Train Epoch: 1 [2444/3396 (72%)]\tLoss: 0.000010\n",
      "Train Epoch: 1 [2496/3396 (73%)]\tLoss: 0.000031\n",
      "Train Epoch: 1 [2548/3396 (75%)]\tLoss: 0.000036\n",
      "Train Epoch: 1 [2600/3396 (77%)]\tLoss: 0.000153\n",
      "Train Epoch: 1 [2652/3396 (78%)]\tLoss: 0.000041\n",
      "Train Epoch: 1 [2704/3396 (80%)]\tLoss: 0.000020\n",
      "Train Epoch: 1 [2756/3396 (81%)]\tLoss: 0.000018\n",
      "Train Epoch: 1 [2808/3396 (83%)]\tLoss: 0.000009\n",
      "Train Epoch: 1 [2860/3396 (84%)]\tLoss: 0.000027\n",
      "Train Epoch: 1 [2912/3396 (86%)]\tLoss: 0.000012\n",
      "Train Epoch: 1 [2964/3396 (87%)]\tLoss: 0.000039\n",
      "Train Epoch: 1 [3016/3396 (89%)]\tLoss: 0.000012\n",
      "Train Epoch: 1 [3068/3396 (90%)]\tLoss: 0.000020\n",
      "Train Epoch: 1 [3120/3396 (92%)]\tLoss: 0.000016\n",
      "Train Epoch: 1 [3172/3396 (93%)]\tLoss: 0.000011\n",
      "Train Epoch: 1 [3224/3396 (95%)]\tLoss: 0.000005\n",
      "Train Epoch: 1 [3276/3396 (96%)]\tLoss: 0.000016\n",
      "Train Epoch: 1 [3328/3396 (98%)]\tLoss: 0.000012\n",
      "Train Epoch: 1 [3380/3396 (100%)]\tLoss: 0.000030\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train the resnet model\"\"\"\n",
    "mo=res\n",
    "mo.to(device)\n",
    "optimizer = torch.optim.Adam(mo.parameters(),lr=0.000005)\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(0, 2):\n",
    "    train(epoch, mo, optimizer,chan1)\n",
    "torch.save(mo.state_dict(), \"model_cnn_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Users\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=800, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=800, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=torchvision.models.resnet50(pretrained=False)\n",
    "\n",
    "model.conv1=nn.Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "print(model.conv1)\n",
    "num_ftrs = model.fc.in_features\n",
    "del model.fc\n",
    "model.add_module(\"fc\", nn.Sequential(nn.Linear(num_ftrs, 800),nn.ReLU(),nn.Linear(800, 200),nn.ReLU(),nn.Linear(200, 12)))\n",
    "\n",
    "model.to('cpu')\n",
    "model1 = model\n",
    "model1.load_state_dict(torch.load('model_cnn_2.pt'))\n",
    "model1.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def lazychoose_test(length):\n",
    "    \"\"\"load testdata and normalize the same way as train\"\"\"\n",
    "    total=[]\n",
    "    for i in range(length):\n",
    "        data=[]\n",
    "        im0=torch.tensor(cv2.normalize(cv2.imread(\"lazydata/test/X/\"+str(i)+\"/rgb/0.png\"), None, alpha=0, beta=1,\n",
    "                             norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F))\n",
    "        \n",
    "        im0=torch.permute(im0,(2,0,1))\n",
    " \n",
    "        im1=torch.tensor(cv2.normalize(cv2.imread(\"lazydata/test/X/\"+str(i)+\"/rgb/1.png\"), None, alpha=0, beta=1,\n",
    "                             norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F))\n",
    "        \n",
    "        im1=torch.permute(im1,(2,0,1))\n",
    "\n",
    "        im2=torch.tensor(cv2.normalize(cv2.imread(\"lazydata/test/X/\"+str(i)+\"/rgb/2.png\"), None, alpha=0, beta=1,\n",
    "                             norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F))\n",
    "        im2=torch.permute(im2,(2,0,1))\n",
    "    \n",
    "        depth=torch.tensor(cv2.normalize(np.load(\"lazydata/test/X/\"+str(i)+\"/depth.npy\"), None, alpha=0, beta=1,\n",
    "                             norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F))\n",
    "        index=pickle.load(open(\"lazydata/test/X/\"+str(i)+\"/field_id.pkl\",\"rb\"))\n",
    "        data.append(im0)\n",
    "        data.append(im1)\n",
    "        data.append(im2)\n",
    "        data.append(depth)\n",
    "        data.append(index)\n",
    "        \n",
    "        total.append(data)\n",
    "    train_loader = torch.utils.data.DataLoader(total, batch_size=64, shuffle=False)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=lazychoose_test(849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for data in test_data:\n",
    "    image=torch.stack((data[0][:,0],data[0][:,1],data[0][:,2],\\\n",
    "            data[1][:,0],data[1][:,1],data[1][:,2],data[2][:,0],data[2][:,1],\\\n",
    "                data[2][:,2],data[3][:,0],data[3][:,1],data[3][:,2]),1)\n",
    "\n",
    "    output = model1(image.to('cpu'))\n",
    "  \n",
    "    preds.append(output.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids=[]\n",
    "for i in test_data:\n",
    "    for j in i[4]:\n",
    "    \n",
    "        file_ids.append(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to csv file submission.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# model=model_cnn\n",
    "outfile = 'submission.csv'\n",
    "\n",
    "output_file = open(outfile, 'w')\n",
    "\n",
    "titles = ['ID', 'FINGER_POS_1', 'FINGER_POS_2', 'FINGER_POS_3', 'FINGER_POS_4', 'FINGER_POS_5', 'FINGER_POS_6',\n",
    "         'FINGER_POS_7', 'FINGER_POS_8', 'FINGER_POS_9', 'FINGER_POS_10', 'FINGER_POS_11', 'FINGER_POS_12']\n",
    "\n",
    "\n",
    "df = pd.concat([pd.DataFrame(file_ids), pd.DataFrame.from_records(np.concatenate(preds))], axis = 1, names = titles)\n",
    "df.columns = titles\n",
    "df.to_csv(outfile, index = False)\n",
    "print(\"Written to csv file {}\".format(outfile))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16855252810840b26444cac0322ddd81b99f38e36fb786ceb15c86ab2fb17a88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
